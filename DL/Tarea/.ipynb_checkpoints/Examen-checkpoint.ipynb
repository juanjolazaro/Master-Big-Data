{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prospective-america",
   "metadata": {},
   "source": [
    "Dado que el entrenamiento de redes neuronales es una tarea  muy costosa, **se recomienda ejecutar el notebooks en [Google Colab](https://colab.research.google.com)**, por supuesto también se puede ejecutar en local.\n",
    "\n",
    "Al entrar en [Google Colab](https://colab.research.google.com) bastará con hacer click en `upload` y subir este notebook. No olvide luego descargarlo en `File->Download .ipynb`\n",
    "\n",
    "**El examen deberá ser entregado con las celdas ejecutadas, si alguna celda no está ejecutadas no se contará.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-stewart",
   "metadata": {},
   "source": [
    "El examen se divide en tres partes, con la puntuación que se indica a continuación. La puntuación máxima será 10.\n",
    "\n",
    "- [Actividad 1: Redes Densas](#actividad_1): 4 pts\n",
    "    - Correcta normalización: máximo de 0.25 pts\n",
    "    - [Cuestión 1](#1.1): 1 pt\n",
    "    - [Cuestión 2](#1.2): 1 pt\n",
    "    - [Cuestión 3](#1.3): 0.5 pts\n",
    "    - [Cuestión 4](#1.4): 0.25 pts\n",
    "    - [Cuestión 5](#1.5): 0.25 pts\n",
    "    - [Cuestión 6](#1.6): 0.25 pts\n",
    "    - [Cuestión 7](#1.7): 0.25 pts\n",
    "    - [Cuestión 8](#1.8): 0.25 pts\n",
    "\n",
    "\n",
    "- [Actividad 2: Redes Convolucionales](#actividad_2): 4 pts\n",
    "    - [Cuestión 1](#2.1): 1 pt\n",
    "    - [Cuestión 2](#2.2): 1.5 pt\n",
    "    - [Cuestión 3](#2.3): 0.5 pts\n",
    "    - [Cuestión 4](#2.4): 0.25 pts\n",
    "    - [Cuestión 5](#2.5): 0.25 pts\n",
    "    - [Cuestión 6](#2.6): 0.25 pts\n",
    "    - [Cuestión 7](#2.7): 0.25 pts\n",
    "    \n",
    "    \n",
    "- [Actividad 3: Redes Recurrentes](#actividad_3): 2 pts\n",
    "    - [Cuestión 1](#3.1): 0.5 pt\n",
    "    - [Cuestión 2](#3.2): 0.5 pt\n",
    "    - [Cuestión 3](#3.3): 0.5 pts\n",
    "    - [Cuestión 4](#3.4): 0.25 pts\n",
    "    - [Cuestión 5](#3.5): 0.25 pts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-correction",
   "metadata": {},
   "source": [
    "<a name='actividad_1'></a>\n",
    "# Actividad 1: Redes Densas\n",
    "\n",
    "Para esta primera actividad vamos a utilizar el [boston housing dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). Con el que trataremos de predecir el precio de una casa con 13 features.\n",
    "\n",
    "**Puntuación**: \n",
    "\n",
    "Normalizar las features correctamente (x_train, x_test): 0.1 pts , 0.25 si se normalizan con el [Normalization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Normalization) de Keras. Ejemplo de uso: [Introduction_to_RNN_Time_Series](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
    "\n",
    "```python\n",
    "tf.keras.layers.experimental.preprocessing.Normalization(\n",
    "    axis=-1, dtype=None, mean=None, variance=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- Correcta normalización: máximo de 0.25 pts\n",
    "- [Cuestión 1](#1.1): 1 pt\n",
    "- [Cuestión 2](#1.2): 1 pt\n",
    "- [Cuestión 3](#1.3): 0.5 pts\n",
    "- [Cuestión 4](#1.4): 0.25 pts\n",
    "- [Cuestión 5](#1.5): 0.25 pts\n",
    "- [Cuestión 6](#1.6): 0.25 pts\n",
    "- [Cuestión 7](#1.7): 0.25 pts\n",
    "- [Cuestión 8](#1.8): 0.25 pts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "presidential-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train, y_train shapes: (404, 13) (404,)\n",
      "x_test, y_test shapes: (404, 13) (404,)\n",
      "Some prices:  [15.2 42.3 50.  21.1 17.7]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz',\n",
    "    test_split=0.2,\n",
    ")\n",
    "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
    "print('x_test, y_test shapes:', x_train.shape, y_train.shape)\n",
    "print('Some prices: ', y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "painted-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Si quiere, puede normalizar las features\n",
    "#JLM->\n",
    "#layer = tf.keras.layers.experimental.preprocessing.Normalization(axis=-1)\n",
    "#layer.adapt(x_train)\n",
    "#x_train_norm=layer(x_train)\n",
    "#print(x_train_norm)\n",
    "\n",
    "\n",
    "#layer.adapt(x_test)\n",
    "#x_test_norm=layer(x_test)\n",
    "#print(x_test_norm)\n",
    "\n",
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    " \n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-planner",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "## Cuestión 1: Cree un modelo secuencial que contenga 4 capas ocultas(hidden layers), con más de 60 neuronas  por capa, sin regularización y obtenga los resultados.\n",
    "\n",
    "Puntuación: \n",
    "- Obtener el modelo correcto: 0.8 pts\n",
    "- Compilar el modelo: 0.1pts\n",
    "- Acertar con la función de pérdida: 0.1 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "working-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "\n",
    "#--> JLM: MAL----------------------------------------------------------------------\n",
    "model.add(layers.Dense(64, activation='relu',input_shape=(13,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense((1), activation='relu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "mobile-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 10.2110 - mae: 2.3521 - val_loss: 11.3384 - val_mae: 2.5768\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.5082 - mae: 2.0649 - val_loss: 10.9539 - val_mae: 2.5801\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2910 - mae: 2.0823 - val_loss: 11.3206 - val_mae: 2.6451\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7919 - mae: 1.9918 - val_loss: 10.8380 - val_mae: 2.5606\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.6905 - mae: 1.9998 - val_loss: 10.6314 - val_mae: 2.5116\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.1056 - mae: 1.8877 - val_loss: 10.5500 - val_mae: 2.4807\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.0961 - mae: 2.0568 - val_loss: 14.3788 - val_mae: 2.8564\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.4577 - mae: 2.2224 - val_loss: 12.9798 - val_mae: 2.7140\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.7405 - mae: 2.0612 - val_loss: 10.7098 - val_mae: 2.5727\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3592 - mae: 1.9562 - val_loss: 10.8670 - val_mae: 2.4451\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8257 - mae: 1.9078 - val_loss: 11.6665 - val_mae: 2.6596\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5397 - mae: 1.8277 - val_loss: 12.0179 - val_mae: 2.6597\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4880 - mae: 2.0149 - val_loss: 10.4048 - val_mae: 2.4238\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1234 - mae: 1.8259 - val_loss: 10.6510 - val_mae: 2.4661\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0339 - mae: 1.9425 - val_loss: 9.8095 - val_mae: 2.3779\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3366 - mae: 2.0100 - val_loss: 10.9039 - val_mae: 2.5358\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6659 - mae: 1.9037 - val_loss: 10.5546 - val_mae: 2.4084\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4530 - mae: 1.8705 - val_loss: 12.7515 - val_mae: 2.7293\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1871 - mae: 1.8068 - val_loss: 9.6551 - val_mae: 2.3322\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5044 - mae: 1.6969 - val_loss: 9.5522 - val_mae: 2.2799\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.4305 - mae: 1.6494 - val_loss: 10.3566 - val_mae: 2.4193\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.4000 - mae: 1.6575 - val_loss: 10.3341 - val_mae: 2.3544\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1414 - mae: 1.6042 - val_loss: 10.6934 - val_mae: 2.4354\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2718 - mae: 1.6203 - val_loss: 10.9210 - val_mae: 2.4850\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2540 - mae: 1.6730 - val_loss: 10.0730 - val_mae: 2.3321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e00aca2f40>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "#--> JLM:\n",
    "#model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "model.compile(optimizer='Adam', loss='mse', metrics=['mae'])\n",
    "model.fit(x_train, y_train, epochs=25, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "rotary-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 5.2291 - mae: 1.6552 - val_loss: 9.7805 - val_mae: 2.2988\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9538 - mae: 1.6007 - val_loss: 9.9007 - val_mae: 2.2801\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.5238 - mae: 1.7372 - val_loss: 13.0663 - val_mae: 2.7518\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9256 - mae: 1.7183 - val_loss: 10.1454 - val_mae: 2.3877\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1493 - mae: 1.6425 - val_loss: 12.4954 - val_mae: 2.5897\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7289 - mae: 2.3029 - val_loss: 15.2715 - val_mae: 3.1873\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.2713 - mae: 2.4087 - val_loss: 11.3535 - val_mae: 2.5377\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8071 - mae: 1.8116 - val_loss: 10.4171 - val_mae: 2.3596\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0322 - mae: 1.6520 - val_loss: 10.2849 - val_mae: 2.4108\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0294 - mae: 1.6263 - val_loss: 10.3446 - val_mae: 2.3484\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6077 - mae: 1.5664 - val_loss: 10.6242 - val_mae: 2.4837\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4192 - mae: 1.5109 - val_loss: 9.7690 - val_mae: 2.2811\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2718 - mae: 1.4981 - val_loss: 9.4450 - val_mae: 2.2512\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4810 - mae: 1.5240 - val_loss: 11.2998 - val_mae: 2.4102\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5527 - mae: 1.5564 - val_loss: 10.7404 - val_mae: 2.4563\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.0864 - mae: 1.4490 - val_loss: 10.1511 - val_mae: 2.3384\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1700 - mae: 1.4789 - val_loss: 9.7962 - val_mae: 2.3067\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4533 - mae: 1.5150 - val_loss: 9.8005 - val_mae: 2.2824\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.9361 - mae: 1.4326 - val_loss: 9.7657 - val_mae: 2.2582\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8454 - mae: 1.4050 - val_loss: 10.2028 - val_mae: 2.2954\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.9016 - mae: 1.4314 - val_loss: 9.4444 - val_mae: 2.2405\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7940 - mae: 1.3878 - val_loss: 9.1847 - val_mae: 2.2025\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.9059 - mae: 1.4499 - val_loss: 9.3687 - val_mae: 2.3312\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6332 - mae: 1.5496 - val_loss: 9.0756 - val_mae: 2.2252\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5527 - mae: 1.5625 - val_loss: 9.4394 - val_mae: 2.2684\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7220 - mae: 1.9394 - val_loss: 16.1909 - val_mae: 3.1369\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3402 - mae: 1.9532 - val_loss: 10.3763 - val_mae: 2.3756\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.0961 - mae: 1.5625 - val_loss: 9.1786 - val_mae: 2.2293\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7534 - mae: 1.4288 - val_loss: 9.1539 - val_mae: 2.2002\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4737 - mae: 1.3409 - val_loss: 9.0910 - val_mae: 2.1993\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5561 - mae: 1.3381 - val_loss: 9.7124 - val_mae: 2.2568\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4030 - mae: 1.3210 - val_loss: 10.1521 - val_mae: 2.2959\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3731 - mae: 1.3116 - val_loss: 9.6892 - val_mae: 2.2767\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2618 - mae: 1.2973 - val_loss: 8.9837 - val_mae: 2.1718\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 3.4341 - mae: 1.3231 - val_loss: 9.6291 - val_mae: 2.2339\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.1761 - mae: 1.2765 - val_loss: 10.0134 - val_mae: 2.2762\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.1753 - mae: 1.2780 - val_loss: 10.0830 - val_mae: 2.2932\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1605 - mae: 1.2826 - val_loss: 9.2354 - val_mae: 2.1856\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2376 - mae: 1.2649 - val_loss: 9.9829 - val_mae: 2.2330\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5106 - mae: 1.3582 - val_loss: 9.7296 - val_mae: 2.2527\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1480 - mae: 1.2652 - val_loss: 11.5740 - val_mae: 2.4963\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.4420 - mae: 1.3578 - val_loss: 9.3565 - val_mae: 2.2386\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2646 - mae: 1.2911 - val_loss: 11.0321 - val_mae: 2.3904\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3000 - mae: 1.3520 - val_loss: 9.8287 - val_mae: 2.3065\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8550 - mae: 1.4454 - val_loss: 9.6514 - val_mae: 2.1848\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.5973 - mae: 1.3710 - val_loss: 9.2430 - val_mae: 2.1637\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.3610 - mae: 1.3741 - val_loss: 9.2238 - val_mae: 2.2158\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5940 - mae: 1.3962 - val_loss: 9.6692 - val_mae: 2.2071\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2346 - mae: 1.5547 - val_loss: 12.6859 - val_mae: 2.6871\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8260 - mae: 1.4582 - val_loss: 11.4974 - val_mae: 2.4427\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0743 - mae: 1.2755 - val_loss: 9.2920 - val_mae: 2.1484\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0101 - mae: 1.2757 - val_loss: 8.8047 - val_mae: 2.1159\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.0212 - mae: 1.2544 - val_loss: 10.3498 - val_mae: 2.2617\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9044 - mae: 1.2253 - val_loss: 9.2538 - val_mae: 2.2073\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8533 - mae: 1.1924 - val_loss: 10.0786 - val_mae: 2.2136\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9871 - mae: 1.2838 - val_loss: 9.4064 - val_mae: 2.2236\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8296 - mae: 1.1972 - val_loss: 10.0966 - val_mae: 2.2312\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5730 - mae: 1.1318 - val_loss: 8.8354 - val_mae: 2.1210\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8681 - mae: 1.2246 - val_loss: 9.8044 - val_mae: 2.2766\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.5308 - mae: 1.4070 - val_loss: 10.2054 - val_mae: 2.3272\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8367 - mae: 1.1970 - val_loss: 10.4453 - val_mae: 2.2958\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7580 - mae: 1.1640 - val_loss: 9.3970 - val_mae: 2.2436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7614 - mae: 1.2178 - val_loss: 9.6069 - val_mae: 2.2070\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8959 - mae: 1.2347 - val_loss: 8.6471 - val_mae: 2.1010\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5497 - mae: 1.1292 - val_loss: 11.2262 - val_mae: 2.3952\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7964 - mae: 1.4562 - val_loss: 9.9344 - val_mae: 2.3183\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9401 - mae: 1.2781 - val_loss: 7.7425 - val_mae: 2.0692\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1068 - mae: 1.2876 - val_loss: 8.4500 - val_mae: 2.1267\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6764 - mae: 1.1900 - val_loss: 9.0576 - val_mae: 2.1924\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6114 - mae: 1.1768 - val_loss: 9.0654 - val_mae: 2.1026\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.7739 - mae: 1.2033 - val_loss: 9.2569 - val_mae: 2.2283\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1263 - mae: 1.2655 - val_loss: 10.7805 - val_mae: 2.3615\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3.5431 - mae: 1.4123 - val_loss: 9.5162 - val_mae: 2.3019\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1391 - mae: 1.2603 - val_loss: 10.9623 - val_mae: 2.3679\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.9513 - mae: 1.2623 - val_loss: 10.0820 - val_mae: 2.2441\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4376 - mae: 1.1447 - val_loss: 8.8568 - val_mae: 2.1212\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.3536 - mae: 1.0961 - val_loss: 8.9656 - val_mae: 2.1205\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4365 - mae: 1.1482 - val_loss: 8.6974 - val_mae: 2.1058\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6501 - mae: 1.1761 - val_loss: 8.8261 - val_mae: 2.1179\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2445 - mae: 1.0679 - val_loss: 8.9310 - val_mae: 2.0914\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4608 - mae: 1.1444 - val_loss: 8.7176 - val_mae: 2.1032\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1169 - mae: 1.0364 - val_loss: 8.7990 - val_mae: 2.0917\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5140 - mae: 1.1448 - val_loss: 8.6684 - val_mae: 2.0851\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2802 - mae: 1.0742 - val_loss: 8.1466 - val_mae: 2.0675\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2660 - mae: 1.0697 - val_loss: 10.5336 - val_mae: 2.3083\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.6126 - mae: 1.1645 - val_loss: 8.5439 - val_mae: 2.0751\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4260 - mae: 1.1161 - val_loss: 9.5211 - val_mae: 2.1998\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5212 - mae: 1.1367 - val_loss: 8.7351 - val_mae: 2.1273\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8525 - mae: 1.2809 - val_loss: 9.0881 - val_mae: 2.1721\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2708 - mae: 1.1009 - val_loss: 8.8434 - val_mae: 2.1002\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0347 - mae: 1.0143 - val_loss: 8.4609 - val_mae: 2.0751\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0138 - mae: 1.0059 - val_loss: 8.9385 - val_mae: 2.1443\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0170 - mae: 1.0205 - val_loss: 8.2398 - val_mae: 2.0730\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.4931 - mae: 1.1423 - val_loss: 9.8071 - val_mae: 2.3071\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0177 - mae: 1.3292 - val_loss: 7.9549 - val_mae: 2.0392\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.2496 - mae: 1.1298 - val_loss: 10.0113 - val_mae: 2.2752\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.5884 - mae: 1.1710 - val_loss: 8.6910 - val_mae: 2.1204\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9623 - mae: 1.3488 - val_loss: 9.1839 - val_mae: 2.1143\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5536 - mae: 1.2030 - val_loss: 9.8374 - val_mae: 2.2300\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 3.2894 - mae: 1.323 - 0s 4ms/step - loss: 2.3558 - mae: 1.1295 - val_loss: 9.4250 - val_mae: 2.1143\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1051 - mae: 1.0482 - val_loss: 8.8194 - val_mae: 2.0569\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.2701 - mae: 1.1072 - val_loss: 9.0194 - val_mae: 2.0848\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.3278 - mae: 1.1192 - val_loss: 8.9226 - val_mae: 2.1652\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0238 - mae: 1.0211 - val_loss: 9.5429 - val_mae: 2.1862\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0121 - mae: 1.0052 - val_loss: 9.4191 - val_mae: 2.2133\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0022 - mae: 1.0260 - val_loss: 8.7713 - val_mae: 2.0702\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8884 - mae: 0.9680 - val_loss: 8.7631 - val_mae: 2.0910\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9390 - mae: 0.9882 - val_loss: 8.6250 - val_mae: 2.0394\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9018 - mae: 0.9741 - val_loss: 8.6275 - val_mae: 2.0510\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0475 - mae: 1.0129 - val_loss: 8.2021 - val_mae: 1.9759\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8298 - mae: 0.9596 - val_loss: 9.0938 - val_mae: 2.1827\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2324 - mae: 1.3058 - val_loss: 11.2476 - val_mae: 2.3706\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5036 - mae: 1.2128 - val_loss: 8.6164 - val_mae: 2.1390\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1712 - mae: 1.1127 - val_loss: 10.0584 - val_mae: 2.2694\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0411 - mae: 1.0332 - val_loss: 9.4894 - val_mae: 2.1746\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8935 - mae: 0.9813 - val_loss: 9.2799 - val_mae: 2.1420\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9124 - mae: 1.0192 - val_loss: 8.4641 - val_mae: 2.0255\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7511 - mae: 0.9506 - val_loss: 8.9439 - val_mae: 2.0970\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5919 - mae: 0.8929 - val_loss: 9.3829 - val_mae: 2.1684\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6722 - mae: 0.9093 - val_loss: 9.3293 - val_mae: 2.1252\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6119 - mae: 0.9037 - val_loss: 9.1685 - val_mae: 2.0814\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7960 - mae: 0.9639 - val_loss: 8.8477 - val_mae: 2.0713\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6804 - mae: 0.9300 - val_loss: 9.0466 - val_mae: 2.1568\n",
      "Epoch 124/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8804 - mae: 1.0246 - val_loss: 8.3108 - val_mae: 1.9779\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7406 - mae: 0.9363 - val_loss: 8.2262 - val_mae: 2.0100\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4007 - mae: 1.1739 - val_loss: 9.2116 - val_mae: 2.1055\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7323 - mae: 0.9247 - val_loss: 8.8094 - val_mae: 2.0819\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8057 - mae: 0.9775 - val_loss: 9.1276 - val_mae: 2.1417\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5756 - mae: 0.8751 - val_loss: 8.9651 - val_mae: 2.0722\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6649 - mae: 0.9267 - val_loss: 8.1229 - val_mae: 1.9998\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9966 - mae: 1.0634 - val_loss: 7.9375 - val_mae: 2.0489\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9268 - mae: 1.0362 - val_loss: 8.1373 - val_mae: 2.0305\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4252 - mae: 1.1202 - val_loss: 9.6293 - val_mae: 2.1958\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5413 - mae: 1.2023 - val_loss: 11.1357 - val_mae: 2.3440\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0689 - mae: 1.0354 - val_loss: 8.8302 - val_mae: 2.1577\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1840 - mae: 1.0725 - val_loss: 8.5398 - val_mae: 2.0481\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7516 - mae: 0.9361 - val_loss: 10.1598 - val_mae: 2.1956\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7364 - mae: 0.9847 - val_loss: 8.2275 - val_mae: 1.9973\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5748 - mae: 0.9100 - val_loss: 9.6039 - val_mae: 2.1761\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7086 - mae: 0.9405 - val_loss: 9.3536 - val_mae: 2.1037\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8177 - mae: 0.9455 - val_loss: 8.3423 - val_mae: 2.0034\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.9564 - mae: 0.989 - 0s 3ms/step - loss: 1.8476 - mae: 0.9656 - val_loss: 9.0324 - val_mae: 2.0474\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4672 - mae: 0.8298 - val_loss: 8.3548 - val_mae: 2.0098\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3547 - mae: 0.7947 - val_loss: 9.2294 - val_mae: 2.1035\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8510 - mae: 0.9708 - val_loss: 9.4545 - val_mae: 2.2281\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8414 - mae: 0.9798 - val_loss: 9.7445 - val_mae: 2.1768\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.5727 - mae: 0.9083 - val_loss: 9.6125 - val_mae: 2.1400\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1.6178 - mae: 0.9207 - val_loss: 8.5529 - val_mae: 2.0086\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5049 - mae: 0.8654 - val_loss: 8.8657 - val_mae: 2.0348\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.3257 - mae: 1.3538 - val_loss: 10.6306 - val_mae: 2.3328\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.0388 - mae: 1.0649 - val_loss: 10.6201 - val_mae: 2.3201\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.1812 - mae: 1.1146 - val_loss: 9.4925 - val_mae: 2.3083\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.8277 - mae: 0.9964 - val_loss: 8.6128 - val_mae: 2.0559\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4204 - mae: 0.8418 - val_loss: 8.9818 - val_mae: 2.0993\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3570 - mae: 0.8119 - val_loss: 8.6701 - val_mae: 2.0475\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.6578 - mae: 0.9060 - val_loss: 9.0588 - val_mae: 2.0425\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3498 - mae: 0.8063 - val_loss: 8.4110 - val_mae: 2.0290\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3608 - mae: 0.8174 - val_loss: 8.4297 - val_mae: 1.9770\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3238 - mae: 0.8047 - val_loss: 8.8611 - val_mae: 2.0300\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3785 - mae: 0.8168 - val_loss: 9.3225 - val_mae: 2.1627\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6889 - mae: 0.9437 - val_loss: 9.2253 - val_mae: 2.0951\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3732 - mae: 0.8336 - val_loss: 8.7977 - val_mae: 2.0471\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3617 - mae: 0.8363 - val_loss: 7.8279 - val_mae: 1.9519\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2609 - mae: 0.7955 - val_loss: 8.9652 - val_mae: 2.0808\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6945 - mae: 0.9192 - val_loss: 8.5568 - val_mae: 2.0828\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9479 - mae: 1.0711 - val_loss: 8.6035 - val_mae: 2.0811\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7910 - mae: 1.0151 - val_loss: 9.5215 - val_mae: 2.1361\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3854 - mae: 0.8555 - val_loss: 8.6704 - val_mae: 2.0277\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4369 - mae: 0.8411 - val_loss: 8.8763 - val_mae: 2.0568\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.6091 - mae: 0.9465 - val_loss: 8.4865 - val_mae: 2.0237\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5749 - mae: 0.8938 - val_loss: 8.6123 - val_mae: 2.0468\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2938 - mae: 0.8267 - val_loss: 8.9653 - val_mae: 2.0555\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2030 - mae: 0.7705 - val_loss: 8.5167 - val_mae: 2.0027\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1228 - mae: 0.7326 - val_loss: 8.3530 - val_mae: 1.9909\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3561 - mae: 0.8349 - val_loss: 8.6830 - val_mae: 2.0164\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2570 - mae: 0.7984 - val_loss: 8.4785 - val_mae: 1.9819\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1605 - mae: 0.7421 - val_loss: 8.4813 - val_mae: 1.9609\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.4745 - mae: 0.8525 - val_loss: 8.2795 - val_mae: 1.9583\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3160 - mae: 0.8252 - val_loss: 9.7279 - val_mae: 2.1250\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.3195 - mae: 0.8313 - val_loss: 9.1061 - val_mae: 2.0466\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2095 - mae: 0.7758 - val_loss: 8.5151 - val_mae: 2.0114\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2194 - mae: 0.7971 - val_loss: 9.3951 - val_mae: 2.0970\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.1625 - mae: 0.7526 - val_loss: 9.6118 - val_mae: 2.1166\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2689 - mae: 0.8266 - val_loss: 8.6699 - val_mae: 2.0125\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3897 - mae: 0.8660 - val_loss: 9.5185 - val_mae: 2.1504\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3175 - mae: 0.8076 - val_loss: 8.6679 - val_mae: 2.0281\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1866 - mae: 0.7877 - val_loss: 9.1574 - val_mae: 2.0691\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1986 - mae: 0.7765 - val_loss: 9.7862 - val_mae: 2.1413\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.3265 - mae: 0.8088 - val_loss: 8.6220 - val_mae: 2.0319\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.7514 - mae: 1.0035 - val_loss: 9.7876 - val_mae: 2.1980\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.9115 - mae: 1.0325 - val_loss: 9.5132 - val_mae: 2.1447\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.5822 - mae: 0.9552 - val_loss: 9.1325 - val_mae: 2.1954\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.4801 - mae: 0.9212 - val_loss: 8.3699 - val_mae: 2.0554\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.2813 - mae: 0.8625 - val_loss: 8.8498 - val_mae: 2.0658\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2126 - mae: 0.8203 - val_loss: 9.4475 - val_mae: 2.1125\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.4638 - mae: 0.8665 - val_loss: 9.2044 - val_mae: 2.0989\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.2385 - mae: 0.7835 - val_loss: 8.8688 - val_mae: 2.0634\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1.1219 - mae: 0.7978 - val_loss: 9.2036 - val_mae: 2.0855\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.0906 - mae: 0.7344 - val_loss: 9.8461 - val_mae: 2.1414\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1.3913 - mae: 0.8301 - val_loss: 9.0726 - val_mae: 2.1218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e00b190370>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No modifique el código\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "descending-letters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 12.2410 - mae: 2.4429\n",
      "Test Loss: [12.240966796875, 2.442910671234131]\n"
     ]
    }
   ],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-delivery",
   "metadata": {},
   "source": [
    "<a name='1.2'></a>\n",
    "## Cuestión 2: Utilice el mismo modelo de la cuestión anterior pero añadiendo al menos dos técnicas distinas de regularización.\n",
    "\n",
    "Ejemplos de regularización: [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb)\n",
    "\n",
    "Puntuación:\n",
    "\n",
    "- Obtener el modelo con la regularización: 0.8 pts\n",
    "- Obtener un `test loss` inferior al anterior: 0.2 pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f8622",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.2,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-vegetation",
   "metadata": {},
   "source": [
    "<a name='1.3'></a>\n",
    "## Cuestión 3: Utilice el mismo modelo de la cuestión anterior pero añadiendo un callback de early stopping. Obtenga un test loss inferior al del modelo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo\n",
    "# Código aquí\n",
    "model.compile(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "## definir el early stopping callback\n",
    "# Código aquí\n",
    "...\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_split=0.2,\n",
    "          verbose=1,\n",
    "          callbacks=[...]) # Código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No modifique el código\n",
    "results = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-lesbian",
   "metadata": {},
   "source": [
    "<a name='1.4'></a>\n",
    "## Cuestión 4: ¿Podría haberse usado otra función de activación de la neurona de salida? En caso afirmativo especifíquela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-silicon",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "robust-christianity",
   "metadata": {},
   "source": [
    "<a name='1.5'></a>\n",
    "## Cuestión 5:  ¿Qué es lo que una neurona calcula?\n",
    "\n",
    "**a)** Una función de activación seguida de una suma ponderada  de las entradas.\n",
    "\n",
    "**b)** Una suma ponderada  de las entradas seguida de una función de activación.\n",
    "\n",
    "**c)** Una función de pérdida, definida sobre el target.\n",
    "\n",
    "**d)** Ninguna  de las anteriores es correcta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-burden",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-european",
   "metadata": {},
   "source": [
    "<a name='1.6'></a>\n",
    "## Cuestión 6:  ¿Cuál de estas funciones de activación no debería usarse en una capa oculta (hidden layer)?\n",
    "\n",
    "**a)** `sigmoid`\n",
    "\n",
    "**b)** `tanh`\n",
    "\n",
    "**c)** `relu`\n",
    "\n",
    "**d)** `linear`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-attack",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ranging-utilization",
   "metadata": {},
   "source": [
    "<a name='1.7'></a>\n",
    "## Cuestión 7:  ¿Cuál de estas técnicas es efectiva para combatir el overfitting en una red con varias capas ocultas? Ponga todas las que lo sean.\n",
    "\n",
    "**a)** Dropout\n",
    "\n",
    "**b)** Regularización L2.\n",
    "\n",
    "**c)** Aumentar el tamaño del test set.\n",
    "\n",
    "**d)** Aumentar el tamaño del validation set.\n",
    "\n",
    "**e)** Reducir el número de capas de la red.\n",
    "\n",
    "**f)** Data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-trainer",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "recreational-deposit",
   "metadata": {},
   "source": [
    "<a name='1.8'></a>\n",
    "## Cuestión 8:  Supongamos que queremos entrenar una red para un problema de clasificación de imágenes con las siguientes clases: {'perro','gato','persona'}. ¿Cuántas neuronas y que función de activación debería tener la capa de salida? ¿Qué función de pérdida (loss function) debería usarse?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-roulette",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "painful-decade",
   "metadata": {},
   "source": [
    "<a name='actividad_2'></a>\n",
    "# Actividad 2: Redes Convolucionales\n",
    "\n",
    "Vamos a usar el dataset [cifar-10](https://www.cs.toronto.edu/~kriz/cifar.html), que son 60000 imágenes de 32x32 a color  con 10 clases diferentes. Para realizar mejor la práctica puede consultar [Introduction_to_CNN.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb).\n",
    "\n",
    "\n",
    "\n",
    "**Puntuación**: \n",
    "\n",
    "- [Cuestión 1](#2.1): 1 pt\n",
    "- [Cuestión 2](#2.2): 1.5 pt\n",
    "- [Cuestión 3](#2.3): 0.5 pts\n",
    "- [Cuestión 4](#2.4): 0.25 pts\n",
    "- [Cuestión 5](#2.5): 0.25 pts\n",
    "- [Cuestión 6](#2.6): 0.25 pts\n",
    "- [Cuestión 7](#2.7): 0.25 pts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Puede normalizar las imágenes al principio o usar la capa [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling):\n",
    "\n",
    "```python\n",
    "tf.keras.layers.experimental.preprocessing.Rescaling(\n",
    "    scale, offset=0.0, name=None, **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "incorporate-terrorist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1355\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1006\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0m\u001b[0;32m   1422\u001b[0m                                                   server_hostname=server_hostname)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# ctx._wrap_socket()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         return self.sslsocket_class._create(\n\u001b[0m\u001b[0;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36m_create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1397\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1398\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3f235db10d21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\cifar10.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[0mdirname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cifar-10-batches-py'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[0morigin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   path = get_file(\n\u001b[0m\u001b[0;32m     53\u001b[0m       \u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m       \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1131)"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train, y_train shapes:', x_train.shape, y_train.shape)\n",
    "print('x_test, y_test shapes:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-philosophy",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "## Cuestión 1: Cree una red convolucional con la API funcional con al menos dos capas convolucionales y al menos dos capas de pooling. Utilize sólo [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y no añada ninguna regularización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "# reescaling = ...\n",
    "\n",
    "# Convolution + pooling layers\n",
    "...\n",
    "\n",
    "# Flattening\n",
    "...\n",
    "\n",
    "# Fully-connected\n",
    "outputs = layers.Dense(...)\n",
    "\n",
    "model = keras.Model(inputs=..., outputs=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=25, batch_size=64,\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-invite",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "## Cuestión 2: Cree un modelo con la API funcional con un máximo de 2 capas convolucionales y un máximo de 2 capas de pooling. Utilize  [Max Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) o [Average Pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) y  añada la regularización que quiera. Debe obtener un `Test accuracy > 0.68`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "# reescaling = ...\n",
    "\n",
    "# Convolution + pooling layers\n",
    "...\n",
    "\n",
    "# Flattening\n",
    "...\n",
    "\n",
    "# Fully-connected\n",
    "outputs = layers.Dense(...)\n",
    "\n",
    "model = keras.Model(inputs=..., outputs=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
    "                    validation_split=0.15, callbacks=lbacks=[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-arizona",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "## Cuestión 3: Añada data augmentation al principio del modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation=... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "data_aug= ...\n",
    "\n",
    "# reescaling = ...\n",
    "\n",
    "# Convolution + pooling layers\n",
    "...\n",
    "\n",
    "# Flattening\n",
    "...\n",
    "\n",
    "# Fully-connected\n",
    "outputs = layers.Dense(...)\n",
    "\n",
    "model = keras.Model(inputs=..., outputs=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, epochs=..., batch_size=...,\n",
    "                    validation_split=0.15, callbacks=lbacks=[...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0, batch_size=1000)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-implement",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "## Cuestión 4: Cree el mismo  modelo de manera secuencial. No es necesario compilar ni entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq = tf.keras.models.Sequential()\n",
    "# Código aquí\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-consortium",
   "metadata": {},
   "source": [
    "<a name='2.5'></a>\n",
    "## Cuestión 5: Si tenenemos una  una imagen de entrada de 300 x 300 a color (RGB) y queremos usar una red densa. Si la primera capa oculta tiene 100 neuronas, ¿Cuántos parámetros tendrá esa capa (sin incluir el bias) ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-calcium",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "complicated-positive",
   "metadata": {},
   "source": [
    "<a name='2.6'></a>\n",
    "## Cuestión 6   Ponga  las verdaderas ventajas de las redes convolucionales respecto a las densas\n",
    "\n",
    "**a)** Reducen el número total de parámetros, reduciendo así el overfitting.\n",
    "\n",
    "**b)** Permiten utilizar una misma 'función'  en varias localizaciones de la imagen de entrada, en lugar de aprender una función diferente para cada pixel.\n",
    "\n",
    "**c)** Permiten el uso del transfer learning.\n",
    "\n",
    "**d)** Generalmente son menos profundas, lo que facilita su entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-nirvana",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "first-toyota",
   "metadata": {},
   "source": [
    "<a name='2.7'></a>\n",
    "## Cuestión 7: Para el procesamiento de series temporales las redes convolucionales no son efectivas, habrá que usar redes recurrentes.\n",
    "\n",
    "- **Verdadero** \n",
    "- **Falso** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-seven",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regional-favorite",
   "metadata": {},
   "source": [
    "<a name='actividad_3'></a>\n",
    "# Actividad 3: Redes Recurrentes\n",
    "\n",
    "\n",
    "- [Cuestión 1](#3.1): 0.5 pt\n",
    "- [Cuestión 2](#3.2): 0.5 pt\n",
    "- [Cuestión 3](#3.3): 0.5 pts\n",
    "- [Cuestión 4](#3.4): 0.25 pts\n",
    "- [Cuestión 5](#3.5): 0.25 pts\n",
    "\n",
    "Vamos a usar un dataset de las temperaturas mínimas diarias en Melbourne. La tarea será la de predecir la temperatura mínima en dos días. Puedes usar técnicas de series temporales vistas en otras asignaturas, pero no es necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
    "data_dir = tf.keras.utils.get_file('daily-min-temperatures.csv', origin=dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir, parse_dates=['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = df['Temp'].values\n",
    "print('number of samples:', len(temperatures))\n",
    "train_data = temperatures[:3000]\n",
    "test_data = temperatures[3000:]\n",
    "print('number of train samples:', len(train_data))\n",
    "print('number of test samples:', len(test_data))\n",
    "print('firsts trainn samples:', train_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-brief",
   "metadata": {},
   "source": [
    "<a name='3.1'></a>\n",
    "## Cuestión 1: Convierta `train_data` y `test_data`  en ventanas de tamaño 5, para predecir el valor en 2 días\n",
    "\n",
    "En la nomenclatura de [Introduction_to_RNN_Time_Series.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/RNN/Introduction_to_RNN_Time_Series.ipynb)\n",
    "```python\n",
    "past, future = (5, 2)\n",
    "```\n",
    "\n",
    "Para las primeras 10 muestras de train_data `[20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20. ]` el resultado debería ser:\n",
    "\n",
    "```python\n",
    "x[0] : [20.7, 17.9, 18.8, 14.6, 15.8] , y[0]: 15.8\n",
    "x[1] : [17.9, 18.8, 14.6, 15.8, 15.8] , y[1]: 17.4\n",
    "x[2] : [18.8, 14.6, 15.8, 15.8, 15.8] , y[2]: 21.8\n",
    "x[3] : [14.6, 15.8, 15.8, 15.8, 17.4] , y[3]: 20.             \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "past, future = (5, 2)\n",
    "X_train, y_train = ...\n",
    "X_test, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-junior",
   "metadata": {},
   "source": [
    "<a name='3.2'></a>\n",
    "## Cuestión 2: Cree un modelo recurrente de dos capas GRU para predecir con las ventanas de la cuestión anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(..., ...))\n",
    "...\n",
    "model = keras.Model(inputs=..., outputs=...)\n",
    "model.compile(...)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-guitar",
   "metadata": {},
   "source": [
    "<a name='3.3'></a>\n",
    "## Cuestión 3: Añada más features a la series temporal, por ejemplo `portion_year`. Cree un modelo que mejore al anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Puede añadir más features\n",
    "df['portion_year'] = df['Date'].dt.dayofyear / 365.0\n",
    "df_multi = df[['Temp', 'portion_year']].copy()\n",
    "\n",
    "## train - test split\n",
    "train_data = df_multi.iloc[:3000].copy()\n",
    "test_data = df_multi.loc[3000:, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create windows\n",
    "X_train, y_train = ...\n",
    "X_test, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(..., ...))\n",
    "...\n",
    "model = keras.Model(inputs=..., outputs=...)\n",
    "model.compile(...)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=0, patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    validation_split=0.2, shuffle=True, batch_size = 64, callbacks=[es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-tract",
   "metadata": {},
   "source": [
    "<a name='3.4'></a>\n",
    "## Cuestión 4: ¿En cuáles de estas aplicaciones se usaría un arquitectura 'many-to-one'?\n",
    "\n",
    "**a)** Clasificación de sentimiento en textos\n",
    "\n",
    "**b)** Verificación de voz para iniciar el ordenador.\n",
    "\n",
    "**c)** Generación de música.\n",
    "\n",
    "**d)** Un clasificador que clasifique piezas de música según su autor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-mayor",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fallen-error",
   "metadata": {},
   "source": [
    "<a name='3.5'></a>\n",
    "## Cuestión 5: ¿Qué ventajas aporta el uso de word embeddings?\n",
    "\n",
    "**a)** Permiten reducir la dimensión de entrada respecto al one-hot encoding.\n",
    "\n",
    "**b)** Permiten descubrir la similaridad entre palabras de manera más intuitiva que con one-hot encoding.\n",
    "\n",
    "**c)** Son una manera de realizar transfer learning en nlp.\n",
    "\n",
    "**d)** Permiten visualizar las relaciones entre palabras con métodos de reducción de dimensioones como el PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-polish",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
